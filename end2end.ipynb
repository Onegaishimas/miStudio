{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4b03e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ miStudio Complete Workflow - Phi-4 SAE Training and Analysis\n",
      "======================================================================\n",
      "Model: microsoft/Phi-4\n",
      "Target Layer: 30\n",
      "Output Directory: /home/sean/app/miStudio/mistudio_phi4_results\n",
      "Service URLs configured:\n",
      "  - Train: http://localhost:8001\n",
      "  - Find: http://localhost:8002\n",
      "  - Explain: http://localhost:8003\n",
      "  - Score: http://localhost:8004\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# miStudio Complete Workflow: Phi-4 SAE Training and Analysis\n",
    "# \n",
    "# This notebook demonstrates the complete miStudio interpretability workflow:\n",
    "# 1. Train a Sparse Autoencoder (SAE) on Microsoft Phi-4 at layer 30\n",
    "# 2. Find and analyze features using miStudioFind\n",
    "# 3. Generate explanations using miStudioExplain  \n",
    "# 4. Score feature importance using miStudioScore\n",
    "#\n",
    "# Prerequisites:\n",
    "# - All miStudio services running on their designated ports\n",
    "# - GPU with sufficient memory (>= 16GB recommended for Phi-4)\n",
    "# - HuggingFace token for accessing gated models (if needed)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "SERVICE_PORTS = {\n",
    "    'train': 8001,\n",
    "    'find': 8002, \n",
    "    'explain': 8003,\n",
    "    'score': 8004\n",
    "}\n",
    "\n",
    "BASE_URL = \"http://localhost\"\n",
    "SERVICE_URLS = {\n",
    "    service: f\"{BASE_URL}:{port}\" \n",
    "    for service, port in SERVICE_PORTS.items()\n",
    "}\n",
    "\n",
    "# Model and training configuration\n",
    "MODEL_NAME = \"microsoft/Phi-4\"\n",
    "TARGET_LAYER = 30  # Layer 30 for Phi-4\n",
    "WEBTEXT_CORPUS_URL = \"https://huggingface.co/datasets/stas/openwebtext-10k/resolve/main/plain_text/train-00000-of-00001.parquet\"\n",
    "CORPUS_FILENAME = \"webtext_corpus.txt\"\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR = Path(\"./mistudio_phi4_results\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Global variables to store results between steps\n",
    "training_job_id = None\n",
    "find_job_id = None\n",
    "explain_job_id = None\n",
    "score_job_id = None\n",
    "\n",
    "print(\"üöÄ miStudio Complete Workflow - Phi-4 SAE Training and Analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Target Layer: {TARGET_LAYER}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR.absolute()}\")\n",
    "print(f\"Service URLs configured:\")\n",
    "for service, url in SERVICE_URLS.items():\n",
    "    print(f\"  - {service.capitalize()}: {url}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Utility functions\n",
    "def check_service_health(service_name: str, url: str) -> bool:\n",
    "    \"\"\"Check if a service is healthy and responsive.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{url}/health\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            health_data = response.json()\n",
    "            print(f\"‚úÖ {service_name.capitalize()} service: {health_data.get('status', 'healthy')}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå {service_name.capitalize()} service: HTTP {response.status_code}\")\n",
    "            return False\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå {service_name.capitalize()} service: Connection failed - {e}\")\n",
    "        return False\n",
    "\n",
    "def wait_for_job_completion(service_url: str, job_id: str, service_name: str, \n",
    "                          max_wait_minutes: int = 120) -> Dict[str, Any]:\n",
    "    \"\"\"Wait for a job to complete and return the final status.\"\"\"\n",
    "    start_time = time.time()\n",
    "    max_wait_seconds = max_wait_minutes * 60\n",
    "    \n",
    "    print(f\"‚è≥ Waiting for {service_name} job {job_id} to complete...\")\n",
    "    \n",
    "    while time.time() - start_time < max_wait_seconds:\n",
    "        try:\n",
    "            response = requests.get(f\"{service_url}/api/v1/{service_name.lower()}/{job_id}/status\")\n",
    "            if response.status_code == 200:\n",
    "                status_data = response.json()\n",
    "                status = status_data.get('status')\n",
    "                \n",
    "                if status == 'completed':\n",
    "                    print(f\"‚úÖ {service_name} job completed successfully!\")\n",
    "                    return status_data\n",
    "                elif status == 'failed':\n",
    "                    print(f\"‚ùå {service_name} job failed!\")\n",
    "                    print(f\"Error: {status_data.get('error', 'Unknown error')}\")\n",
    "                    return status_data\n",
    "                elif status in ['running', 'queued']:\n",
    "                    progress = status_data.get('progress', {})\n",
    "                    if 'percentage' in progress:\n",
    "                        print(f\"üîÑ {service_name} progress: {progress['percentage']:.1f}% - {progress.get('message', '')}\")\n",
    "                    else:\n",
    "                        print(f\"üîÑ {service_name} status: {status}\")\n",
    "                    time.sleep(30)  # Check every 30 seconds\n",
    "                else:\n",
    "                    print(f\"üîÑ {service_name} status: {status}\")\n",
    "                    time.sleep(30)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Failed to get {service_name} status: HTTP {response.status_code}\")\n",
    "                time.sleep(30)\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"‚ö†Ô∏è Error checking {service_name} status: {e}\")\n",
    "            time.sleep(30)\n",
    "    \n",
    "    print(f\"‚è∞ Timeout waiting for {service_name} job to complete after {max_wait_minutes} minutes\")\n",
    "    return {'status': 'timeout'}\n",
    "\n",
    "def download_webtext_corpus() -> str:\n",
    "    \"\"\"Download and prepare the webtext corpus for training.\"\"\"\n",
    "    corpus_path = OUTPUT_DIR / CORPUS_FILENAME\n",
    "    \n",
    "    if corpus_path.exists():\n",
    "        print(f\"üìÅ Webtext corpus already exists: {corpus_path}\")\n",
    "        return str(corpus_path)\n",
    "    \n",
    "    print(\"üì• Downloading webtext corpus...\")\n",
    "    try:\n",
    "        # Download the parquet file\n",
    "        parquet_path = OUTPUT_DIR / \"webtext.parquet\"\n",
    "        urllib.request.urlretrieve(WEBTEXT_CORPUS_URL, parquet_path)\n",
    "        \n",
    "        # Convert parquet to text format\n",
    "        import pandas as pd\n",
    "        df = pd.read_parquet(parquet_path)\n",
    "        \n",
    "        # Extract text content and create a plain text file\n",
    "        with open(corpus_path, 'w', encoding='utf-8') as f:\n",
    "            for text in df['text'].head(1000):  # Use first 1000 samples for demo\n",
    "                if isinstance(text, str) and len(text.strip()) > 50:\n",
    "                    # Clean and write text\n",
    "                    clean_text = text.strip().replace('\\n', ' ').replace('\\r', ' ')\n",
    "                    f.write(clean_text + '\\n')\n",
    "        \n",
    "        # Clean up parquet file\n",
    "        parquet_path.unlink()\n",
    "        \n",
    "        print(f\"‚úÖ Webtext corpus prepared: {corpus_path}\")\n",
    "        print(f\"üìä Corpus size: {corpus_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "        \n",
    "        return str(corpus_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to download webtext corpus: {e}\")\n",
    "        # Create a fallback corpus\n",
    "        print(\"üìù Creating fallback corpus...\")\n",
    "        fallback_texts = [\n",
    "            \"The quick brown fox jumps over the lazy dog.\",\n",
    "            \"Artificial intelligence is transforming how we work and live.\",\n",
    "            \"Machine learning models require large datasets for training.\",\n",
    "            \"Natural language processing helps computers understand text.\",\n",
    "            \"Deep learning uses neural networks with multiple layers.\",\n",
    "            \"Transformers have revolutionized natural language understanding.\",\n",
    "            \"Sparse autoencoders help us understand what neural networks learn.\",\n",
    "            \"Feature interpretability is crucial for AI safety and alignment.\",\n",
    "        ] * 100  # Repeat to create more content\n",
    "        \n",
    "        with open(corpus_path, 'w', encoding='utf-8') as f:\n",
    "            for text in fallback_texts:\n",
    "                f.write(text + '\\n')\n",
    "        \n",
    "        print(f\"‚úÖ Fallback corpus created: {corpus_path}\")\n",
    "        return str(corpus_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a96bbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè• STEP 0: SERVICE HEALTH CHECKS\n",
      "--------------------------------------------------\n",
      "‚úÖ Train service: healthy\n",
      "‚ùå Find service: Connection failed - HTTPConnectionPool(host='localhost', port=8002): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7e8ca6191550>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "‚ùå Explain service: Connection failed - HTTPConnectionPool(host='localhost', port=8003): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7e8c8fb9f920>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "‚ùå Score service: Connection failed - HTTPConnectionPool(host='localhost', port=8004): Max retries exceeded with url: /health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7e8c8fbd01a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "‚ùå Some services are not healthy. Please ensure all miStudio services are running.\n",
      "Expected services:\n",
      "  - miStudioTrain: port 8001\n",
      "  - miStudioFind: port 8002\n",
      "  - miStudioExplain: port 8003\n",
      "  - miStudioScore: port 8004\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/app/miStudio/miStudio-dev-env/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Health Checks\n",
    "print(\"\\nüè• STEP 0: SERVICE HEALTH CHECKS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_services_healthy = True\n",
    "for service_name, service_url in SERVICE_URLS.items():\n",
    "    if not check_service_health(service_name, service_url):\n",
    "        all_services_healthy = False\n",
    "\n",
    "if not all_services_healthy:\n",
    "    print(\"\\n‚ùå Some services are not healthy. Please ensure all miStudio services are running.\")\n",
    "    print(\"Expected services:\")\n",
    "    for service, port in SERVICE_PORTS.items():\n",
    "        print(f\"  - miStudio{service.capitalize()}: port {port}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"\\n‚úÖ All services are healthy and ready!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c07cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• STEP 1: CORPUS PREPARATION\n",
      "--------------------------------------------------\n",
      "üìÅ Webtext corpus already exists: mistudio_phi4_results/webtext_corpus.txt\n",
      "üì§ Uploading corpus to training service...\n",
      "üìÅ Current files in samples directory: 0\n",
      "‚úÖ Corpus uploaded successfully: webtext_corpus.txt\n",
      "üìä Size: 0.0 MB\n",
      "üìÑ Lines: 801\n",
      "üìã Upload Response: {'status': 'success', 'message': 'File uploaded successfully', 'filename': 'webtext_corpus.txt', 'file_path': '/data/samples/webtext_corpus.txt', 'file_size_bytes': 48300, 'estimated_lines': 801, 'ready_for_training': True}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Download and prepare corpus\n",
    "print(\"\\nüì• STEP 1: CORPUS PREPARATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "corpus_path = download_webtext_corpus()\n",
    "\n",
    "# Upload corpus to training service\n",
    "print(\"üì§ Uploading corpus to training service...\")\n",
    "\n",
    "# First, check if we can list existing files (this will help debug permissions)\n",
    "try:\n",
    "    list_response = requests.get(f\"{SERVICE_URLS['train']}/api/v1/files\")\n",
    "    if list_response.status_code == 200:\n",
    "        files_info = list_response.json()\n",
    "        print(f\"üìÅ Current files in samples directory: {len(files_info.get('files', []))}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Cannot list files: HTTP {list_response.status_code}\")\n",
    "        print(\"This might indicate a permission or directory issue\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error checking files: {e}\")\n",
    "\n",
    "# Try to upload the corpus\n",
    "try:\n",
    "    with open(corpus_path, 'rb') as f:\n",
    "        files = {'file': (CORPUS_FILENAME, f, 'text/plain')}\n",
    "        response = requests.post(f\"{SERVICE_URLS['train']}/api/v1/upload\", files=files)\n",
    "        \n",
    "    if response.status_code == 200:\n",
    "        upload_result = response.json()\n",
    "        print(f\"‚úÖ Corpus uploaded successfully: {upload_result.get('filename', 'webtext_corpus.txt')}\")\n",
    "        \n",
    "        # Handle different possible response formats\n",
    "        size_bytes = upload_result.get('size_bytes') or upload_result.get('file_size_bytes')\n",
    "        if size_bytes:\n",
    "            print(f\"üìä Size: {size_bytes / 1024 / 1024:.1f} MB\")\n",
    "        \n",
    "        lines_count = upload_result.get('lines_count') or upload_result.get('estimated_lines')\n",
    "        if lines_count:\n",
    "            print(f\"üìÑ Lines: {lines_count}\")\n",
    "        \n",
    "        print(f\"üìã Upload Response: {upload_result}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to upload corpus: HTTP {response.status_code}\")\n",
    "        error_response = response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text\n",
    "        print(f\"Error details: {error_response}\")\n",
    "        \n",
    "        # If it's a permission error, provide helpful guidance\n",
    "        if \"Permission denied\" in str(error_response):\n",
    "            print(\"\\nüîß PERMISSION FIX NEEDED:\")\n",
    "            print(\"The miStudioTrain service cannot write to /data/samples directory.\")\n",
    "            print(\"Please run one of these commands on your server:\")\n",
    "            print(\"  sudo mkdir -p /data/samples\")\n",
    "            print(\"  sudo chmod 777 /data/samples\")\n",
    "            print(\"OR\")\n",
    "            print(\"  sudo chown -R $USER:$USER /data\")\n",
    "            print(\"\\nAlternatively, check your Docker/Kubernetes volume mounts.\")\n",
    "            \n",
    "        sys.exit(1)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error uploading corpus: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7bc8643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèãÔ∏è STEP 2: SAE TRAINING\n",
      "--------------------------------------------------\n",
      "üöÄ Starting SAE training job...\n",
      "üìã Configuration:\n",
      "  - Model: microsoft/Phi-4\n",
      "  - Target Layer: 30\n",
      "  - Hidden Dimensions: 1024\n",
      "  - Batch Size: 8\n",
      "  - Max Epochs: 20\n",
      "‚úÖ Training job started: train_20250730_010840_8341\n",
      "üìä Job Details:\n",
      "  - Status: queued\n",
      "  - Model: microsoft/Phi-4\n",
      "  - Memory Check: passed\n",
      "  - Optimizations: Applied optimizations for microsoft/Phi-4: True\n",
      "‚è≥ Waiting for Train job train_20250730_010840_8341 to complete...\n",
      "‚úÖ Train job completed successfully!\n",
      "üéØ Training completed successfully!\n",
      "üìä Training Results:\n",
      "  - Final Loss: N/A\n",
      "  - Epochs Completed: N/A\n",
      "  - Output Directory: N/A\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Train SAE\n",
    "print(\"\\nüèãÔ∏è STEP 2: SAE TRAINING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "train_request = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"corpus_file\": CORPUS_FILENAME,\n",
    "    \"layer_number\": TARGET_LAYER,\n",
    "    \"hidden_dim\": 1024,\n",
    "    \"sparsity_coeff\": 1e-3,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 8,  # Conservative batch size for Phi-4\n",
    "    \"max_epochs\": 20,\n",
    "    \"min_loss\": 0.01,\n",
    "    \"max_sequence_length\": 512,\n",
    "    \"gpu_id\": 0  # Use first GPU\n",
    "}\n",
    "\n",
    "print(f\"üöÄ Starting SAE training job...\")\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"  - Model: {MODEL_NAME}\")\n",
    "print(f\"  - Target Layer: {TARGET_LAYER}\")\n",
    "print(f\"  - Hidden Dimensions: {train_request['hidden_dim']}\")\n",
    "print(f\"  - Batch Size: {train_request['batch_size']}\")\n",
    "print(f\"  - Max Epochs: {train_request['max_epochs']}\")\n",
    "\n",
    "try:\n",
    "    response = requests.post(f\"{SERVICE_URLS['train']}/api/v1/train\", json=train_request)\n",
    "    \n",
    "    if response.status_code in [200, 202]:  # Accept both 200 and 202 as success\n",
    "        train_result = response.json()\n",
    "        training_job_id = train_result['job_id']\n",
    "        print(f\"‚úÖ Training job started: {training_job_id}\")\n",
    "        print(f\"üìä Job Details:\")\n",
    "        print(f\"  - Status: {train_result.get('status')}\")\n",
    "        print(f\"  - Model: {train_result.get('model_name')}\")\n",
    "        print(f\"  - Memory Check: {train_result.get('memory_check')}\")\n",
    "        print(f\"  - Optimizations: {train_result.get('optimizations_applied')}\")\n",
    "        \n",
    "        # Wait for training completion\n",
    "        final_status = wait_for_job_completion(\n",
    "            SERVICE_URLS['train'], training_job_id, 'Train', max_wait_minutes=180\n",
    "        )\n",
    "        \n",
    "        if final_status.get('status') == 'completed':\n",
    "            print(f\"üéØ Training completed successfully!\")\n",
    "            \n",
    "            # Get training results\n",
    "            result_response = requests.get(f\"{SERVICE_URLS['train']}/api/v1/train/{training_job_id}/result\")\n",
    "            if result_response.status_code == 200:\n",
    "                training_results = result_response.json()\n",
    "                print(f\"üìä Training Results:\")\n",
    "                print(f\"  - Final Loss: {training_results.get('final_loss', 'N/A')}\")\n",
    "                print(f\"  - Epochs Completed: {training_results.get('epochs_completed', 'N/A')}\")\n",
    "                print(f\"  - Output Directory: {training_results.get('output_dir', 'N/A')}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Could not retrieve training results\")\n",
    "        else:\n",
    "            print(f\"‚ùå Training failed or timed out\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚ùå Failed to start training: HTTP {response.status_code}\")\n",
    "        print(response.text)\n",
    "        sys.exit(1)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during training: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eac575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature Analysis with miStudioFind\n",
    "print(\"\\nüîç STEP 3: FEATURE ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "find_request = {\n",
    "    \"source_job_id\": training_job_id,\n",
    "    \"top_k\": 20,\n",
    "    \"coherence_threshold\": 0.5,\n",
    "    \"include_statistics\": True\n",
    "}\n",
    "\n",
    "print(f\"üîé Starting feature analysis...\")\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"  - Source Job: {training_job_id}\")\n",
    "print(f\"  - Top K Activations: {find_request['top_k']}\")\n",
    "print(f\"  - Coherence Threshold: {find_request['coherence_threshold']}\")\n",
    "\n",
    "try:\n",
    "    response = requests.post(f\"{SERVICE_URLS['find']}/api/v1/find/start\", json=find_request)\n",
    "    \n",
    "    if response.status_code == 202:\n",
    "        find_result = response.json()\n",
    "        find_job_id = find_result['job_id']\n",
    "        print(f\"‚úÖ Feature analysis job started: {find_job_id}\")\n",
    "        \n",
    "        # Wait for analysis completion\n",
    "        final_status = wait_for_job_completion(\n",
    "            SERVICE_URLS['find'], find_job_id, 'Find', max_wait_minutes=30\n",
    "        )\n",
    "        \n",
    "        if final_status.get('status') == 'completed':\n",
    "            print(f\"üéØ Feature analysis completed!\")\n",
    "            \n",
    "            # Get analysis results\n",
    "            result_response = requests.get(f\"{SERVICE_URLS['find']}/api/v1/find/{find_job_id}/results\")\n",
    "            if result_response.status_code == 200:\n",
    "                analysis_results = result_response.json()\n",
    "                print(f\"üìä Analysis Results:\")\n",
    "                print(f\"  - Features Analyzed: {analysis_results.get('total_features', 'N/A')}\")\n",
    "                print(f\"  - High Quality Features: {analysis_results.get('high_quality_count', 'N/A')}\")\n",
    "                print(f\"  - Medium Quality Features: {analysis_results.get('medium_quality_count', 'N/A')}\")\n",
    "                print(f\"  - Processing Time: {analysis_results.get('processing_time_seconds', 'N/A')}s\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Could not retrieve analysis results\")\n",
    "        else:\n",
    "            print(f\"‚ùå Feature analysis failed or timed out\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚ùå Failed to start feature analysis: HTTP {response.status_code}\")\n",
    "        print(response.text)\n",
    "        sys.exit(1)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during feature analysis: {e}\")\n",
    "    sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate Explanations with miStudioExplain\n",
    "print(\"\\nüí° STEP 4: EXPLANATION GENERATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "explain_request = {\n",
    "    \"request_id\": f\"phi4_explain_{int(time.time())}\",\n",
    "    \"analysis_type\": \"complex_behavioral\",\n",
    "    \"complexity\": \"medium\",\n",
    "    \"model\": \"llama3.1:8b\",  # Specify local LLM model\n",
    "    \"input_data\": {\n",
    "        \"find_job_id\": find_job_id,\n",
    "        \"feature_analysis\": {},  # Will be populated by service\n",
    "        \"summary_report\": f\"Feature analysis results from job {find_job_id}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"üí¨ Starting explanation generation...\")\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"  - Source Analysis: {find_job_id}\")\n",
    "print(f\"  - Analysis Type: {explain_request['analysis_type']}\")\n",
    "print(f\"  - Complexity: {explain_request['complexity']}\")\n",
    "print(f\"  - LLM Model: {explain_request['model']}\")\n",
    "\n",
    "try:\n",
    "    response = requests.post(f\"{SERVICE_URLS['explain']}/api/v1/explain\", json=explain_request)\n",
    "    \n",
    "    if response.status_code == 202:\n",
    "        explain_result = response.json()\n",
    "        explain_job_id = explain_result['job_id']\n",
    "        print(f\"‚úÖ Explanation generation job started: {explain_job_id}\")\n",
    "        \n",
    "        # Wait for explanation completion\n",
    "        final_status = wait_for_job_completion(\n",
    "            SERVICE_URLS['explain'], explain_job_id, 'Explain', max_wait_minutes=60\n",
    "        )\n",
    "        \n",
    "        if final_status.get('status') == 'completed':\n",
    "            print(f\"üéØ Explanation generation completed!\")\n",
    "            \n",
    "            # Get explanation results\n",
    "            result_response = requests.get(f\"{SERVICE_URLS['explain']}/api/v1/explain/{explain_job_id}/results\")\n",
    "            if result_response.status_code == 200:\n",
    "                explanation_results = result_response.json()\n",
    "                print(f\"üìä Explanation Results:\")\n",
    "                print(f\"  - Explanations Generated: {explanation_results.get('total_explanations', 'N/A')}\")\n",
    "                print(f\"  - Average Quality Score: {explanation_results.get('average_quality_score', 'N/A')}\")\n",
    "                print(f\"  - Processing Time: {explanation_results.get('processing_time_seconds', 'N/A')}s\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Could not retrieve explanation results\")\n",
    "        else:\n",
    "            print(f\"‚ùå Explanation generation failed or timed out\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚ùå Failed to start explanation generation: HTTP {response.status_code}\")\n",
    "        print(response.text)\n",
    "        sys.exit(1)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during explanation generation: {e}\")\n",
    "    sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Score Features with miStudioScore\n",
    "print(\"\\nüìä STEP 5: FEATURE SCORING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create scoring configuration\n",
    "scoring_config = {\n",
    "    \"scoring_jobs\": [\n",
    "        {\n",
    "            \"scorer\": \"relevance_scorer\",\n",
    "            \"name\": \"ai_safety_relevance\",\n",
    "            \"params\": {\n",
    "                \"positive_keywords\": [\n",
    "                    \"safety\", \"security\", \"harmful\", \"dangerous\", \"toxic\",\n",
    "                    \"bias\", \"discrimination\", \"privacy\", \"ethical\"\n",
    "                ],\n",
    "                \"negative_keywords\": [\n",
    "                    \"marketing\", \"advertising\", \"promotion\", \"sales\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"scorer\": \"relevance_scorer\", \n",
    "            \"name\": \"technical_relevance\",\n",
    "            \"params\": {\n",
    "                \"positive_keywords\": [\n",
    "                    \"algorithm\", \"computation\", \"function\", \"method\",\n",
    "                    \"processing\", \"analysis\", \"logic\", \"reasoning\"\n",
    "                ],\n",
    "                \"negative_keywords\": [\n",
    "                    \"emotion\", \"feeling\", \"opinion\", \"preference\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "score_request = {\n",
    "    \"features_path\": f\"data/output/{find_job_id}/features.json\",\n",
    "    \"config_path\": \"config/scoring_config.yaml\",\n",
    "    \"output_dir\": f\"data/output/{find_job_id}\"\n",
    "}\n",
    "\n",
    "print(f\"üìà Starting feature scoring...\")\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"  - Features Source: {find_job_id}\")\n",
    "print(f\"  - Scoring Jobs: {len(scoring_config['scoring_jobs'])}\")\n",
    "print(f\"  - Safety Relevance: {len(scoring_config['scoring_jobs'][0]['params']['positive_keywords'])} keywords\")\n",
    "print(f\"  - Technical Relevance: {len(scoring_config['scoring_jobs'][1]['params']['positive_keywords'])} keywords\")\n",
    "\n",
    "try:\n",
    "    response = requests.post(f\"{SERVICE_URLS['score']}/api/v1/score\", json=score_request)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        score_result = response.json()\n",
    "        print(f\"‚úÖ Feature scoring completed!\")\n",
    "        print(f\"üìä Scoring Results:\")\n",
    "        print(f\"  - Features Scored: {score_result.get('features_scored', 'N/A')}\")\n",
    "        print(f\"  - Scores Added: {', '.join(score_result.get('scores_added', []))}\")\n",
    "        print(f\"  - Output Path: {score_result.get('output_path', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to complete feature scoring: HTTP {response.status_code}\")\n",
    "        print(response.text)\n",
    "        sys.exit(1)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during feature scoring: {e}\")\n",
    "    sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Results Summary and Export\n",
    "print(\"\\nüìã STEP 6: RESULTS SUMMARY AND EXPORT\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(f\"üéâ Complete miStudio workflow finished successfully!\")\n",
    "print(f\"\")\n",
    "print(f\"üìÇ Job IDs:\")\n",
    "print(f\"  - Training: {training_job_id}\")\n",
    "print(f\"  - Feature Analysis: {find_job_id}\")\n",
    "print(f\"  - Explanations: {explain_job_id}\")\n",
    "print(f\"\")\n",
    "print(f\"üìÅ Results available in:\")\n",
    "print(f\"  - Local Output: {OUTPUT_DIR.absolute()}\")\n",
    "print(f\"  - Service Data: /data/output/{find_job_id}/\")\n",
    "print(f\"\")\n",
    "\n",
    "# Export comprehensive results\n",
    "print(f\"üì¶ Exporting comprehensive results...\")\n",
    "\n",
    "try:\n",
    "    # Export feature analysis results in multiple formats\n",
    "    export_response = requests.get(f\"{SERVICE_URLS['find']}/api/v1/find/{find_job_id}/export?format=all\")\n",
    "    if export_response.status_code == 200:\n",
    "        # Save the ZIP file\n",
    "        zip_path = OUTPUT_DIR / f\"phi4_layer{TARGET_LAYER}_complete_results.zip\"\n",
    "        with open(zip_path, 'wb') as f:\n",
    "            f.write(export_response.content)\n",
    "        print(f\"‚úÖ Complete results exported: {zip_path}\")\n",
    "        \n",
    "        # Extract and display summary\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(OUTPUT_DIR / \"extracted_results\")\n",
    "        \n",
    "        print(f\"üìä Exported formats:\")\n",
    "        for file_path in (OUTPUT_DIR / \"extracted_results\").iterdir():\n",
    "            if file_path.is_file():\n",
    "                size_mb = file_path.stat().st_size / 1024 / 1024\n",
    "                print(f\"  - {file_path.name}: {size_mb:.1f} MB\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Could not export results: HTTP {export_response.status_code}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error exporting results: {e}\")\n",
    "\n",
    "print(f\"\")\n",
    "print(f\"‚úÖ WORKFLOW COMPLETE!\")\n",
    "print(f\"\")\n",
    "print(f\"üîç To explore your results:\")\n",
    "print(f\"  1. Check the extracted_results folder for detailed analysis\")\n",
    "print(f\"  2. Review the features.json file for feature mappings\")\n",
    "print(f\"  3. Examine explanations.json for human-readable descriptions\")\n",
    "print(f\"  4. Analyze scores.json for feature importance rankings\")\n",
    "print(f\"\")\n",
    "print(f\"üîó Access service UIs:\")\n",
    "for service, url in SERVICE_URLS.items():\n",
    "    print(f\"  - {service.capitalize()}: {url}/docs\")\n",
    "print(f\"\")\n",
    "print(f\"üìà This completes the full miStudio interpretability pipeline!\")\n",
    "print(f\"   You now have a trained SAE, feature analysis, explanations, and scores\")\n",
    "print(f\"   for the Microsoft Phi-4 model at layer {TARGET_LAYER}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miStudio-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
