{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6102d455",
   "metadata": {},
   "source": [
    "miStudio Complete End-to-End Pipeline (2025)\n",
    "\n",
    "This notebook demonstrates the complete miStudio interpretability workflow:\n",
    "1. Health checks for all services\n",
    "2. Train a Sparse Autoencoder (SAE) on Microsoft Phi-4 at layer 30\n",
    "3. Find and analyze features using miStudioFind\n",
    "4. Generate explanations using miStudioExplain  \n",
    "5. Score feature importance using miStudioScore\n",
    "6. Export and analyze complete results\n",
    "\n",
    "Prerequisites:\n",
    "- All miStudio services running on their designated ports\n",
    "- GPU with sufficient memory (>= 16GB recommended for Phi-4)\n",
    "- Training data prepared (webtext corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e4b03e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ miStudio Complete Workflow - Phi-4 SAE Training and Analysis\n",
      "======================================================================\n",
      "Model: microsoft/Phi-4\n",
      "Target Layer: 30\n",
      "Output Directory: /home/sean/app/miStudio/mistudio_phi4_results\n",
      "Service URLs configured:\n",
      "  - Train: http://localhost:8001\n",
      "  - Find: http://localhost:8002\n",
      "  - Explain: http://localhost:8003\n",
      "  - Score: http://localhost:8004\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# miStudio Complete Workflow - Phi-4 SAE Training and Analysis\n",
    "# This script orchestrates the entire workflow for training, finding, explaining, and scoring a model using miStudio services.\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "SERVICE_PORTS = {\n",
    "    'train': 8001,\n",
    "    'find': 8002, \n",
    "    'explain': 8003,\n",
    "    'score': 8004\n",
    "}\n",
    "\n",
    "BASE_URL = \"http://localhost\"\n",
    "SERVICE_URLS = {\n",
    "    service: f\"{BASE_URL}:{port}\" \n",
    "    for service, port in SERVICE_PORTS.items()\n",
    "}\n",
    "\n",
    "# Model and training configuration\n",
    "MODEL_NAME = \"microsoft/Phi-4\"\n",
    "TARGET_LAYER = 30  # Layer 30 for Phi-4\n",
    "WEBTEXT_CORPUS_URL = \"https://huggingface.co/datasets/stas/openwebtext-10k/resolve/main/plain_text/train-00000-of-00001.parquet\"\n",
    "CORPUS_FILENAME = \"webtext_corpus.txt\"\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR = Path(\"./mistudio_phi4_results\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Global variables to store results between steps\n",
    "training_job_id = None\n",
    "find_job_id = None\n",
    "explain_job_id = None\n",
    "score_job_id = None\n",
    "\n",
    "print(\"üöÄ miStudio Complete Workflow - Phi-4 SAE Training and Analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Target Layer: {TARGET_LAYER}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR.absolute()}\")\n",
    "print(f\"Service URLs configured:\")\n",
    "for service, url in SERVICE_URLS.items():\n",
    "    print(f\"  - {service.capitalize()}: {url}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =============================================================================\n",
    "# Utility Functions\n",
    "# =============================================================================\n",
    "\n",
    "def check_service_health(service_name: str, url: str) -> bool:\n",
    "    \"\"\"Check if a service is healthy and responsive.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{url}/health\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            health_data = response.json()\n",
    "            print(f\"‚úÖ {service_name.capitalize()} service: {health_data.get('status', 'healthy')}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå {service_name.capitalize()} service: HTTP {response.status_code}\")\n",
    "            return False\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå {service_name.capitalize()} service: Connection failed - {e}\")\n",
    "        return False\n",
    "\n",
    "def wait_for_job_completion(service_url: str, job_id: str, service_name: str, \n",
    "                          max_wait_minutes: int = 120) -> Dict[str, Any]:\n",
    "    \"\"\"Wait for a job to complete and return the final status.\"\"\"\n",
    "    start_time = time.time()\n",
    "    max_wait_seconds = max_wait_minutes * 60\n",
    "    \n",
    "    print(f\"‚è≥ Waiting for {service_name} job {job_id} to complete...\")\n",
    "    \n",
    "    while time.time() - start_time < max_wait_seconds:\n",
    "        try:\n",
    "            response = requests.get(f\"{service_url}/api/v1/{service_name.lower()}/{job_id}/status\")\n",
    "            if response.status_code == 200:\n",
    "                status_data = response.json()\n",
    "                status = status_data.get('status')\n",
    "                \n",
    "                if status == 'completed':\n",
    "                    print(f\"‚úÖ {service_name} job completed successfully!\")\n",
    "                    return status_data\n",
    "                elif status == 'failed':\n",
    "                    print(f\"‚ùå {service_name} job failed!\")\n",
    "                    print(f\"Error: {status_data.get('error', 'Unknown error')}\")\n",
    "                    return status_data\n",
    "                elif status in ['running', 'queued']:\n",
    "                    progress = status_data.get('progress', {})\n",
    "                    if 'percentage' in progress:\n",
    "                        print(f\"üîÑ {service_name} progress: {progress['percentage']:.1f}% - {progress.get('message', '')}\")\n",
    "                    else:\n",
    "                        print(f\"üîÑ {service_name} status: {status}\")\n",
    "                    time.sleep(30)  # Check every 30 seconds\n",
    "                else:\n",
    "                    print(f\"üîÑ {service_name} status: {status}\")\n",
    "                    time.sleep(30)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Failed to get {service_name} status: HTTP {response.status_code}\")\n",
    "                time.sleep(30)\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"‚ö†Ô∏è Error checking {service_name} status: {e}\")\n",
    "            time.sleep(30)\n",
    "    \n",
    "    print(f\"‚è∞ Timeout waiting for {service_name} job to complete after {max_wait_minutes} minutes\")\n",
    "    return {'status': 'timeout'}\n",
    "\n",
    "def download_webtext_corpus() -> str:\n",
    "    \"\"\"Download and prepare the webtext corpus for training.\"\"\"\n",
    "    corpus_path = OUTPUT_DIR / CORPUS_FILENAME\n",
    "    \n",
    "    if corpus_path.exists():\n",
    "        print(f\"üìÅ Webtext corpus already exists: {corpus_path}\")\n",
    "        return str(corpus_path)\n",
    "    \n",
    "    print(\"üì• Downloading webtext corpus...\")\n",
    "    \n",
    "    try:\n",
    "        # Download parquet file\n",
    "        parquet_path = OUTPUT_DIR / \"webtext.parquet\"\n",
    "        urllib.request.urlretrieve(WEBTEXT_CORPUS_URL, parquet_path)\n",
    "        \n",
    "        # Convert to text format\n",
    "        import pandas as pd\n",
    "        df = pd.read_parquet(parquet_path)\n",
    "        \n",
    "        with open(corpus_path, 'w', encoding='utf-8') as f:\n",
    "            for text in df['text'].head(1000):  # Use first 1000 texts\n",
    "                if text and len(text.strip()) > 50:  # Filter short texts\n",
    "                    f.write(text.strip() + '\\n')\n",
    "        \n",
    "        # Clean up parquet file\n",
    "        parquet_path.unlink()\n",
    "        \n",
    "        print(f\"‚úÖ Webtext corpus created: {corpus_path}\")\n",
    "        return str(corpus_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error downloading corpus: {e}\")\n",
    "        print(\"üîÑ Creating fallback corpus...\")\n",
    "        \n",
    "        # Create fallback corpus\n",
    "        fallback_texts = [\n",
    "            \"Transformers have revolutionized natural language understanding.\",\n",
    "            \"Sparse autoencoders help us understand what neural networks learn.\",\n",
    "            \"Feature interpretability is crucial for AI safety and alignment.\",\n",
    "        ] * 100  # Repeat to create more content\n",
    "        \n",
    "        with open(corpus_path, 'w', encoding='utf-8') as f:\n",
    "            for text in fallback_texts:\n",
    "                f.write(text + '\\n')\n",
    "        \n",
    "        print(f\"‚úÖ Fallback corpus created: {corpus_path}\")\n",
    "        return str(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a96bbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè• STEP 0: SERVICE HEALTH CHECKS\n",
      "--------------------------------------------------\n",
      "‚úÖ Train service: healthy\n",
      "‚úÖ Find service: healthy\n",
      "‚úÖ Explain service: healthy\n",
      "‚úÖ Score service: healthy\n",
      "\n",
      "‚úÖ All services are healthy! Proceeding with workflow...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 0: Service Health Checks\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüè• STEP 0: SERVICE HEALTH CHECKS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_healthy = True\n",
    "for service_name, service_url in SERVICE_URLS.items():\n",
    "    is_healthy = check_service_health(service_name, service_url)\n",
    "    if not is_healthy:\n",
    "        all_healthy = False\n",
    "\n",
    "if not all_healthy:\n",
    "    print(\"\\n‚ùå Some services are not healthy.\")\n",
    "    print(\"Please ensure all miStudio services are running before proceeding.\")\n",
    "    print(\"Start services with:\")\n",
    "    for service in SERVICE_PORTS.keys():\n",
    "        print(f\"  cd ~/app/miStudio/services/miStudio{service.capitalize()}\")\n",
    "        print(f\"  ./scripts/dev.sh\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"\\n‚úÖ All services are healthy! Proceeding with workflow...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4c07cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã STEP 1: TRAINING DATA PREPARATION\n",
      "--------------------------------------------------\n",
      "üìÅ Webtext corpus already exists: mistudio_phi4_results/webtext_corpus.txt\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 1: Prepare Training Data\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã STEP 1: TRAINING DATA PREPARATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "corpus_path = download_webtext_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7bc8643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training job started: train_20250801_035441_8498\n",
      "üìä Job Details:\n",
      "  - Status: queued\n",
      "  - Model: microsoft/Phi-4\n",
      "  - Memory Check: passed\n",
      "  - Optimizations: Applied optimizations for microsoft/Phi-4: True\n",
      "‚è≥ Waiting for Train job train_20250801_035441_8498 to complete...\n",
      "‚úÖ Train job completed successfully!\n",
      "üéØ Training completed successfully!\n",
      "üìä Training Results:\n",
      "  - Final Loss: N/A\n",
      "  - Epochs Completed: N/A\n",
      "  - Features: 1024\n",
      "  - Ready for Find: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 2: Train SAE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüèãÔ∏è STEP 2: SAE TRAINING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "train_request = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"corpus_file\": CORPUS_FILENAME,\n",
    "    \"layer_number\": TARGET_LAYER,\n",
    "    \"hidden_dim\": 1024,\n",
    "    \"sparsity_coeff\": 1e-3,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 8,  # Conservative batch size for Phi-4\n",
    "    \"max_epochs\": 20,\n",
    "    \"min_loss\": 0.01,\n",
    "    \"max_sequence_length\": 512,\n",
    "    \"gpu_id\": 0  # Use first GPU\n",
    "}\n",
    "\n",
    "print(f\"üöÄ Starting SAE training job...\")\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"  - Model: {MODEL_NAME}\")\n",
    "print(f\"  - Target Layer: {TARGET_LAYER}\")\n",
    "print(f\"  - Hidden Dimensions: {train_request['hidden_dim']}\")\n",
    "print(f\"  - Batch Size: {train_request['batch_size']}\")\n",
    "print(f\"  - Max Epochs: {train_request['max_epochs']}\")\n",
    "\n",
    "try:\n",
    "    response = requests.post(f\"{SERVICE_URLS['train']}/api/v1/train\", json=train_request)\n",
    "    \n",
    "    if response.status_code in [200, 202]:  # Accept both 200 and 202 as success\n",
    "        train_result = response.json()\n",
    "        training_job_id = train_result['job_id']\n",
    "        print(f\"‚úÖ Training job started: {training_job_id}\")\n",
    "        print(f\"üìä Job Details:\")\n",
    "        print(f\"  - Status: {train_result.get('status')}\")\n",
    "        print(f\"  - Model: {train_result.get('model_name')}\")\n",
    "        print(f\"  - Memory Check: {train_result.get('memory_check')}\")\n",
    "        print(f\"  - Optimizations: {train_result.get('optimizations_applied')}\")\n",
    "        \n",
    "        # Wait for training completion\n",
    "        final_status = wait_for_job_completion(\n",
    "            SERVICE_URLS['train'], training_job_id, 'Train', max_wait_minutes=180\n",
    "        )\n",
    "        \n",
    "        if final_status.get('status') == 'completed':\n",
    "            print(f\"üéØ Training completed successfully!\")\n",
    "            \n",
    "            # Get training results\n",
    "            result_response = requests.get(f\"{SERVICE_URLS['train']}/api/v1/train/{training_job_id}/result\")\n",
    "            if result_response.status_code == 200:\n",
    "                training_results = result_response.json()\n",
    "                print(f\"üìä Training Results:\")\n",
    "                print(f\"  - Final Loss: {training_results.get('final_loss', 'N/A')}\")\n",
    "                print(f\"  - Epochs Completed: {training_results.get('training_stats', {}).get('total_epochs', 'N/A')}\")\n",
    "                print(f\"  - Features: {training_results.get('feature_count', 'N/A')}\")\n",
    "                print(f\"  - Ready for Find: {training_results.get('ready_for_find_service', False)}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Could not retrieve training results\")\n",
    "        else:\n",
    "            print(f\"‚ùå Training failed or timed out\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚ùå Failed to start training: HTTP {response.status_code}\")\n",
    "        print(response.text)\n",
    "        sys.exit(1)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during training: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2eac575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç STEP 3: FEATURE ANALYSIS\n",
      "--------------------------------------------------\n",
      "üîé Starting feature analysis...\n",
      "üìã Configuration:\n",
      "  - Source Job: train_20250801_035441_8498\n",
      "  - Top K Activations: 20\n",
      "  - Coherence Threshold: 0.5\n",
      "‚úÖ Feature analysis job started: find_20250801_035657_79d4cc16\n",
      "‚è≥ Waiting for Find job find_20250801_035657_79d4cc16 to complete...\n",
      "‚úÖ Find job completed successfully!\n",
      "üéØ Feature analysis completed!\n",
      "üìä Analysis Results:\n",
      "  - Features Analyzed: 1024\n",
      "  - Interpretable Features: N/A\n",
      "  - Mean Coherence: N/A\n",
      "  - Ready for Explain: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 3: Feature Analysis with miStudioFind\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüîç STEP 3: FEATURE ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "find_request = {\n",
    "    \"source_job_id\": training_job_id,\n",
    "    \"top_k\": 20,\n",
    "    \"coherence_threshold\": 0.5,\n",
    "    \"include_statistics\": True\n",
    "}\n",
    "\n",
    "print(f\"üîé Starting feature analysis...\")\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"  - Source Job: {training_job_id}\")\n",
    "print(f\"  - Top K Activations: {find_request['top_k']}\")\n",
    "print(f\"  - Coherence Threshold: {find_request['coherence_threshold']}\")\n",
    "\n",
    "try:\n",
    "    response = requests.post(f\"{SERVICE_URLS['find']}/api/v1/find/analyze\", json=find_request)\n",
    "    \n",
    "    if response.status_code in [202, 200]:  # Accept both 202 and 200 as success\n",
    "        # Start feature analysis job\n",
    "        find_result = response.json()\n",
    "        find_job_id = find_result['job_id']\n",
    "        print(f\"‚úÖ Feature analysis job started: {find_job_id}\")\n",
    "        \n",
    "        # Wait for analysis completion\n",
    "        final_status = wait_for_job_completion(\n",
    "            SERVICE_URLS['find'], find_job_id, 'Find', max_wait_minutes=30\n",
    "        )\n",
    "        \n",
    "        if final_status.get('status') == 'completed':\n",
    "            print(f\"üéØ Feature analysis completed!\")\n",
    "            \n",
    "            # Get analysis results\n",
    "            result_response = requests.get(f\"{SERVICE_URLS['find']}/api/v1/find/{find_job_id}/results\")\n",
    "            if result_response.status_code in [200, 202]:  # Accept both 200 and 202 as success\n",
    "                find_results = result_response.json()\n",
    "                print(f\"üìä Analysis Results:\")\n",
    "                print(f\"  - Features Analyzed: {find_results.get('summary', {}).get('total_features_analyzed', find_results.get('feature_count', 'N/A'))}\")\n",
    "                print(f\"  - Interpretable Features: {find_results.get('summary', {}).get('interpretable_features', 'N/A')}\")\n",
    "                \n",
    "                # Handle mean coherence with proper formatting\n",
    "                mean_coherence = find_results.get('summary', {}).get('mean_coherence_score', 'N/A')\n",
    "                if isinstance(mean_coherence, (int, float)):\n",
    "                    print(f\"  - Mean Coherence: {mean_coherence:.3f}\")\n",
    "                else:\n",
    "                    print(f\"  - Mean Coherence: {mean_coherence}\")\n",
    "                \n",
    "                print(f\"  - Ready for Explain: {find_results.get('ready_for_explain_service', True)}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Could not retrieve analysis results\")\n",
    "        else:\n",
    "            print(f\"‚ùå Feature analysis failed or timed out\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚ùå Failed to start feature analysis: HTTP {response.status_code}\")\n",
    "        print(response.text)\n",
    "        sys.exit(1)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during feature analysis: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f65c967a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ STEP 4: EXPLANATION GENERATION\n",
      "--------------------------------------------------\n",
      "üß† Starting explanation generation...\n",
      "üìã Configuration:\n",
      "  - Source Find Job: find_20250801_035657_79d4cc16\n",
      "  - Max Explanations: 50\n",
      "  - Model: llama3.2:3b\n",
      "‚úÖ Explanation generation job started: explain_20250801_035657_5f5f0d4c\n",
      "‚è≥ Waiting for Explain job explain_20250801_035657_5f5f0d4c to complete...\n",
      "üîÑ Explain status: running\n",
      "‚úÖ Explain job completed successfully!\n",
      "üéØ Explanation generation completed!\n",
      "üìä Explanation Results:\n",
      "  - Explanations Generated: N/A\n",
      "  - Average Quality Score: N/A\n",
      "  - Processing Time: N/As\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 4: Generate Explanations with miStudioExplain\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüí¨ STEP 4: EXPLANATION GENERATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "explain_request = {\n",
    "    \"find_job_id\": find_job_id,\n",
    "    \"model\": \"llama3.2:3b\",  # Use available Ollama model\n",
    "    \"max_explanations\": 50,\n",
    "    \"quality_threshold\": 0.5\n",
    "}\n",
    "\n",
    "print(f\"üß† Starting explanation generation...\")\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"  - Source Find Job: {find_job_id}\")\n",
    "print(f\"  - Max Explanations: {explain_request['max_explanations']}\")\n",
    "print(f\"  - Model: {explain_request['model']}\")\n",
    "\n",
    "try:\n",
    "    response = requests.post(f\"{SERVICE_URLS['explain']}/api/v1/explain\", json=explain_request)\n",
    "\n",
    "    if response.status_code in [202, 200]:  # Accept both 202 and 200 as success\n",
    "        explain_result = response.json()\n",
    "        explain_job_id = explain_result['job_id']\n",
    "        print(f\"‚úÖ Explanation generation job started: {explain_job_id}\")\n",
    "        \n",
    "        # Wait for explanation completion\n",
    "        final_status = wait_for_job_completion(\n",
    "            SERVICE_URLS['explain'], explain_job_id, 'Explain', max_wait_minutes=60\n",
    "        )\n",
    "        \n",
    "        if final_status.get('status') == 'completed':\n",
    "            print(f\"üéØ Explanation generation completed!\")\n",
    "            \n",
    "            # Get explanation results\n",
    "            result_response = requests.get(f\"{SERVICE_URLS['explain']}/api/v1/explain/{explain_job_id}/results\")\n",
    "            if result_response.status_code in [200, 202]:  # Accept both 200 and 202 as success\n",
    "                explanation_results = result_response.json()\n",
    "                print(f\"üìä Explanation Results:\")\n",
    "                print(f\"  - Explanations Generated: {explanation_results.get('total_explanations', 'N/A')}\")\n",
    "                print(f\"  - Average Quality Score: {explanation_results.get('average_quality_score', 'N/A')}\")\n",
    "                print(f\"  - Processing Time: {explanation_results.get('processing_time_seconds', 'N/A')}s\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Could not retrieve explanation results\")\n",
    "        else:\n",
    "            print(f\"‚ùå Explanation generation failed or timed out\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚ùå Failed to start explanation generation: HTTP {response.status_code}\")\n",
    "        print(response.text)\n",
    "        sys.exit(1)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during explanation generation: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d3a3b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STEP 5: FEATURE SCORING\n",
      "--------------------------------------------------\n",
      "üéØ Starting feature scoring...\n",
      "üìã Configuration:\n",
      "  - Source Explain Job: explain_20250801_035657_5f5f0d4c\n",
      "  - Scoring Jobs: 2\n",
      "  - Scorers: ['relevance_scorer', 'ablation_scorer']\n",
      "‚úÖ Feature scoring job started: score_20250801_035727_04625c7c\n",
      "‚è≥ Waiting for Score job score_20250801_035727_04625c7c to complete...\n",
      "‚úÖ Score job completed successfully!\n",
      "üéØ Feature scoring completed!\n",
      "üìä Scoring Results:\n",
      "  - Scores Added: ['security_relevance', 'technical_complexity']\n",
      "  - Total Features: 0\n",
      "  - Processing Time: 0.000618s\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Step 5: Score Features with miStudioScore\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìä STEP 5: FEATURE SCORING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create scoring configuration\n",
    "scoring_config = {\n",
    "    \"scoring_jobs\": [\n",
    "        {\n",
    "            \"name\": \"security_relevance\",\n",
    "            \"scorer\": \"relevance_scorer\",\n",
    "            \"parameters\": {\n",
    "                \"positive_keywords\": [\"security\", \"authentication\", \"encryption\", \"privacy\", \"access\"],\n",
    "                \"negative_keywords\": [\"decoration\", \"style\", \"cosmetic\", \"visual\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"technical_complexity\",\n",
    "            \"scorer\": \"ablation_scorer\",\n",
    "            \"parameters\": {\n",
    "                \"threshold\": 0.3,\n",
    "                \"analysis_type\": \"complexity_assessment\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "score_request = {\n",
    "    \"source_type\": \"explain\",\n",
    "    \"source_job_id\": explain_job_id,\n",
    "    \"scoring_config\": scoring_config,\n",
    "    \"output_formats\": [\"json\", \"csv\"]\n",
    "}\n",
    "\n",
    "print(f\"üéØ Starting feature scoring...\")\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"  - Source Explain Job: {explain_job_id}\")\n",
    "print(f\"  - Scoring Jobs: {len(scoring_config['scoring_jobs'])}\")\n",
    "print(f\"  - Scorers: {[job['scorer'] for job in scoring_config['scoring_jobs']]}\")\n",
    "\n",
    "try:\n",
    "    response = requests.post(f\"{SERVICE_URLS['score']}/api/v1/score/analyze\", json=score_request)\n",
    "\n",
    "    if response.status_code in [200, 202]:  # Accept both 200 and 202 as success   \n",
    "        score_result = response.json()\n",
    "        score_job_id = score_result['job_id']\n",
    "        print(f\"‚úÖ Feature scoring job started: {score_job_id}\")\n",
    "        \n",
    "        # Wait for scoring completion\n",
    "        final_status = wait_for_job_completion(\n",
    "            SERVICE_URLS['score'], score_job_id, 'Score', max_wait_minutes=30\n",
    "        )\n",
    "        \n",
    "        if final_status.get('status') == 'completed':\n",
    "            print(f\"üéØ Feature scoring completed!\")\n",
    "            \n",
    "            # Get scoring results\n",
    "            result_response = requests.get(f\"{SERVICE_URLS['score']}/api/v1/score/{score_job_id}/results\")\n",
    "            if result_response.status_code in [200, 202]:  # Accept both 200 and 202 as success\n",
    "                scoring_results = result_response.json()\n",
    "                print(f\"üìä Scoring Results:\")\n",
    "                print(f\"  - Scores Added: {scoring_results.get('scores_added', [])}\")\n",
    "                print(f\"  - Total Features: {scoring_results.get('results_summary', {}).get('total_features', 'N/A')}\")\n",
    "                print(f\"  - Processing Time: {scoring_results.get('processing_time', 'N/A')}s\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Could not retrieve scoring results\")\n",
    "        else:\n",
    "            print(f\"‚ùå Feature scoring failed or timed out\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚ùå Failed to start feature scoring: HTTP {response.status_code}\")\n",
    "        print(response.text)\n",
    "        sys.exit(1)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during feature scoring: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02dc5992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã STEP 6: RESULTS SUMMARY AND EXPORT\n",
      "--------------------------------------------------\n",
      "üéâ Complete miStudio workflow finished successfully!\n",
      "\n",
      "üìÇ Job IDs:\n",
      "  - Training: train_20250801_035441_8498\n",
      "  - Feature Analysis: find_20250801_035657_79d4cc16\n",
      "  - Explanations: explain_20250801_035657_5f5f0d4c\n",
      "  - Feature Scoring: score_20250801_035727_04625c7c\n",
      "\n",
      "üìÅ Results available in shared data directory:\n",
      "  - Training: /data/results/train/train_20250801_035441_8498/\n",
      "  - Find: /data/results/find/find_20250801_035657_79d4cc16/\n",
      "  - Explain: /data/results/explain/explain_20250801_035657_5f5f0d4c/\n",
      "  - Score: /data/results/score/score_20250801_035727_04625c7c/\n",
      "\n",
      "üì¶ Exporting comprehensive results...\n",
      "\n",
      "‚úÖ WORKFLOW COMPLETE!\n",
      "\n",
      "üîç To explore your results:\n",
      "  1. Check the mistudio_phi4_results folder for exported files\n",
      "  2. Review JSON results for detailed feature data\n",
      "  3. Open CSV files in spreadsheet software for analysis\n",
      "  4. Use the job IDs to access results via API endpoints\n",
      "\n",
      "üìä Next steps:\n",
      "  - Analyze feature patterns in the CSV data\n",
      "  - Review explanation quality and coverage\n",
      "  - Use scoring results to identify high-value features\n",
      "  - Consider re-running with different parameters for refinement\n",
      "\n",
      "üéØ Pipeline completed successfully for microsoft/Phi-4 layer 30!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Step 6: Results Summary and Export\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã STEP 6: RESULTS SUMMARY AND EXPORT\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(f\"üéâ Complete miStudio workflow finished successfully!\")\n",
    "print(f\"\")\n",
    "print(f\"üìÇ Job IDs:\")\n",
    "print(f\"  - Training: {training_job_id}\")\n",
    "print(f\"  - Feature Analysis: {find_job_id}\")\n",
    "print(f\"  - Explanations: {explain_job_id}\")\n",
    "print(f\"  - Feature Scoring: {score_job_id}\")\n",
    "print(f\"\")\n",
    "print(f\"üìÅ Results available in shared data directory:\")\n",
    "print(f\"  - Training: /data/results/train/{training_job_id}/\")\n",
    "print(f\"  - Find: /data/results/find/{find_job_id}/\")\n",
    "print(f\"  - Explain: /data/results/explain/{explain_job_id}/\")\n",
    "print(f\"  - Score: /data/results/score/{score_job_id}/\")\n",
    "print(f\"\")\n",
    "\n",
    "# Export comprehensive results\n",
    "print(f\"üì¶ Exporting comprehensive results...\")\n",
    "\n",
    "try:\n",
    "    # Download scoring results (JSON and CSV)\n",
    "    json_response = requests.get(f\"{SERVICE_URLS['score']}/api/v1/score/{score_job_id}/download/json\")\n",
    "    if json_response.status_code in [200, 202]:  # Accept both 200 and 202 as success\n",
    "        json_path = OUTPUT_DIR / f\"phi4_layer{TARGET_LAYER}_scoring_results.json\"\n",
    "        with open(json_path, 'wb') as f:\n",
    "            f.write(json_response.content)\n",
    "        print(f\"‚úÖ Scoring results (JSON): {json_path}\")\n",
    "    \n",
    "    csv_response = requests.get(f\"{SERVICE_URLS['score']}/api/v1/score/{score_job_id}/download/csv\")\n",
    "    if csv_response.status_code in [200, 202]:  # Accept both 200 and 202 as success\n",
    "        csv_path = OUTPUT_DIR / f\"phi4_layer{TARGET_LAYER}_scoring_results.csv\"\n",
    "        with open(csv_path, 'wb') as f:\n",
    "            f.write(csv_response.content)\n",
    "        print(f\"‚úÖ Scoring results (CSV): {csv_path}\")\n",
    "    \n",
    "    # Try to export Find results if available\n",
    "    try:\n",
    "        find_export_response = requests.get(f\"{SERVICE_URLS['find']}/api/v1/find/{find_job_id}/export?format=all\")\n",
    "        if find_export_response.status_code in [200, 202]:  # Accept both 200 and 202 as success\n",
    "            zip_path = OUTPUT_DIR / f\"phi4_layer{TARGET_LAYER}_find_results.zip\"\n",
    "            with open(zip_path, 'wb') as f:\n",
    "                f.write(find_export_response.content)\n",
    "            print(f\"‚úÖ Find results (ZIP): {zip_path}\")\n",
    "    except:\n",
    "        print(f\"‚ö†Ô∏è Could not export Find results (may not be implemented)\")\n",
    "    \n",
    "    # Try to export Explain results if available  \n",
    "    try:\n",
    "        explain_export_response = requests.get(f\"{SERVICE_URLS['explain']}/api/v1/explain/{explain_job_id}/download/all\")\n",
    "        if explain_export_response.status_code in [200, 202]:  # Accept both 200 and 202 as success\n",
    "            explain_zip_path = OUTPUT_DIR / f\"phi4_layer{TARGET_LAYER}_explanations.zip\"\n",
    "            with open(explain_zip_path, 'wb') as f:\n",
    "                f.write(explain_export_response.content)\n",
    "            print(f\"‚úÖ Explanation results (ZIP): {explain_zip_path}\")\n",
    "    except:\n",
    "        print(f\"‚ö†Ô∏è Could not export Explain results (may not be implemented)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error exporting results: {e}\")\n",
    "\n",
    "print(f\"\")\n",
    "print(f\"‚úÖ WORKFLOW COMPLETE!\")\n",
    "print(f\"\")\n",
    "print(f\"üîç To explore your results:\")\n",
    "print(f\"  1. Check the {OUTPUT_DIR.name} folder for exported files\")\n",
    "print(f\"  2. Review JSON results for detailed feature data\")\n",
    "print(f\"  3. Open CSV files in spreadsheet software for analysis\")\n",
    "print(f\"  4. Use the job IDs to access results via API endpoints\")\n",
    "print(f\"\")\n",
    "print(f\"üìä Next steps:\")\n",
    "print(f\"  - Analyze feature patterns in the CSV data\")\n",
    "print(f\"  - Review explanation quality and coverage\")\n",
    "print(f\"  - Use scoring results to identify high-value features\")\n",
    "print(f\"  - Consider re-running with different parameters for refinement\")\n",
    "print(f\"\")\n",
    "print(f\"üéØ Pipeline completed successfully for {MODEL_NAME} layer {TARGET_LAYER}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miStudio-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
